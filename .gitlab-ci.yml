stages:
  - report
  - plot
  - commit
  - test

# run tests only for merge requests
# not necessary to commit reports in that case
grid_test:
  stage: test
  image: gitlab-registry.cern.ch/vaustrup/rucio-clients:latest
  before_script:
    - mkdir -p ${HOME}/.globus
    - base64 -d $USERCERT > ${HOME}/.globus/usercert.pem
    - base64 -d $USERKEY > ${HOME}/.globus/userkey.pem
    - chmod 600 ${HOME}/.globus/userkey.pem
    - export X509_USER_PROXY=X509_USER_PROXY
    - echo $PASSWORD | voms-proxy-init -voms atlas --out /builds/vaustrup/exoticsdiskspaceusage/$X509_USER_PROXY
    - export RUCIO_ACCOUNT=vaustrup
  script:
    - python3 gridspace.py --rse TOKYO-LCG2_PHYS-EXOTICS
  retry: 1 # sometimes there are issues e.g. when pulling docker image
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"

eos_test:
  stage: test
  image: python:3.12.0b2-slim-buster
  before_script:
    - apt-get update
    - apt-get install -y sshpass
  script:
    - python3 eos.py -s cdm --sshpass
  retry: 1 # sometimes there are issues e.g. when pulling docker image
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"

# create and commit all reports only on daily schedule
grid:
  stage: report
  image: gitlab-registry.cern.ch/vaustrup/rucio-clients:latest
  before_script:
    - mkdir -p ${HOME}/.globus
    - base64 -d $USERCERT > ${HOME}/.globus/usercert.pem
    - base64 -d $USERKEY > ${HOME}/.globus/userkey.pem
    - chmod 600 ${HOME}/.globus/userkey.pem
    - export X509_USER_PROXY=X509_USER_PROXY
    - echo $PASSWORD | voms-proxy-init -voms atlas --out /builds/vaustrup/exoticsdiskspaceusage/$X509_USER_PROXY
    - export RUCIO_ACCOUNT=vaustrup
  script:
    - python3 gridspace.py --rse $DISK
  parallel:
    matrix:
      - DISK: [CERN-PROD_PHYS-EXOTICS, TOKYO-LCG2_PHYS-EXOTICS]
  artifacts:
    paths:
      - ./reports/$DISK.csv
    expire_in: 24h
  retry: 1 # sometimes there are issues e.g. when pulling docker image
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"

eos:
  stage: report
  image: python:3.12.0b2-slim-buster
  before_script:
    - apt-get update
    - apt-get install -y sshpass
  script:
    - python3 eos.py -s $SUBGROUP --sshpass
  parallel:
    matrix:
      - SUBGROUP: [cdm, hqt, jdm, lpx, ueh]
  artifacts:
    paths:
      - ./reports/$SUBGROUP.csv
    expire_in: 24h
  retry: 1 # sometimes there are issues e.g. when pulling docker image
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"

plot:
  stage: plot
  image: python:3.12.0b2-slim-buster
  before_script:
    - python3 -m venv venv
    - source venv/bin/activate
    - pip install --upgrade pip
    - pip install matplotlib
  script:
    - python plots.py
  artifacts:
    paths:
      - ./reports/*.pdf
    expire_in: 24h
  retry: 1 # sometimes there are issues e.g. when pulling docker image
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
  allow_failure: True

commit:
  stage: commit
  image: python:3.12.0b2-slim-buster
  before_script:
    - apt-get update
    - apt-get install -y git
  script:
    - git config user.email "exotics.diskspace.watcher@cern.ch"
    - git config user.name "ExoticsDiskspaceWatcher"
    - git remote add gitlab_origin https://oauth2:$ACCESS_TOKEN@gitlab.cern.ch/vaustrup/exoticsdiskspaceusage.git
    - git add reports/*.csv
    - git add reports/*.table
    # - git add reports/*.pdf
    # commit and push only if changes present
    # https://stackoverflow.com/questions/22040113/how-to-let-jenkins-git-commit-only-if-there-are-changes
    - git diff --staged --quiet || (git commit -m "update subgroup data (`date +'%Y-%m-%d'`)" && git push -o ci.skip gitlab_origin HEAD:main)
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
